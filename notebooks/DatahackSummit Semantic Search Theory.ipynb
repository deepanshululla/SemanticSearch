{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e03b93",
   "metadata": {},
   "source": [
    "# Building Your Own Search Engine Using Vector Databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e8918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T08:40:26.682054Z",
     "start_time": "2023-07-05T08:40:26.542951Z"
    }
   },
   "source": [
    "![img](https://www.analyticsvidhya.com/datahack-summit-2023/wp-content/uploads/2023/07/s-won_searchengin.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef2022",
   "metadata": {},
   "source": [
    "## Agenda \n",
    "\n",
    "**Part 0: The Beginning**\n",
    "\n",
    "Welcome and Objectives : An introduction to the session's aims, a brief ice breaker activity, and setting the stage for the exploration ahead.\n",
    "\n",
    "Context Setting: A quick overview of AI, Search Engines, the current landscape, potential use-cases, benefits, and challenges. Highlight the significance of building an AI search engine with your data.\n",
    "\n",
    "**Part 1: Understanding the Basics**\n",
    "\n",
    "NLP and Search Engines: Explore the components like Natural Language Processing (NLP), Machine Learning algorithms, and their roles in crafting an efficient AI search engine. Topics include\n",
    "\n",
    "\n",
    "- What are vector embeddings?\n",
    "- Legacy vectorizing techniques like CountVectorizer, bag of words\n",
    "- Similarity measures and how do they work\n",
    "- LLM and Transformers\n",
    "\n",
    "Vector Databases\n",
    "  - An Exploration:\n",
    "  - Unveiling Vector Databases\n",
    "  - Understanding their workings\n",
    "  - Real-world use-cases\n",
    "  - A comparative analysis of available options\n",
    "\n",
    "**Part 2: Indexing**\n",
    "\n",
    "Splitting the data : Why is it required and different kinds of Data splitting. Also cover why splitting is context dependent (i.e depends on data)\n",
    "\n",
    "The next step is to insert the data into the database\n",
    "\n",
    "\n",
    "**Part 3: Searching**\n",
    "\n",
    "Performing Semantic Search on Indexed Data: Discuss and code the integration of NLP and Machine Learning algorithms into the search engine to comprehend, analyze, and generate precise search results from the given data. Employ Command line tools (or maybe a GUI) to execute the searches.\n",
    "\n",
    "Discuss Different Retrieval algorithms such as\n",
    "* MMR\n",
    "* LLM Aided Retrieval\n",
    "* Compression\n",
    "\n",
    "**Part 4: Question and answering**\n",
    "\n",
    "- Prompt Engineering and templates \n",
    "- Addressing a lot of windows and short context windows\n",
    "\n",
    "**Part 5: Chat**\n",
    "\n",
    "- Introducing memory\n",
    "- Followup conversations\n",
    "\n",
    "\n",
    "**Wrap-Up and Next Steps**\n",
    "\n",
    "Conclusion and Future Directions: Discuss steps to enhance the solution and where to go from here, providing a clear path for continued exploration and development.\n",
    "\n",
    "**References and Resources**\n",
    "\n",
    "\n",
    "## Checkbox\n",
    "\n",
    "\n",
    "### Demo Checkbox\n",
    "\n",
    "- [X]  **Part 1: Understanding the Basics**\n",
    "- [X]  **Part 2: Indexing**\n",
    "- [X]  **Part 3: Semantic search with vector db**\n",
    "- [X]  **Part 4: Question and answering**\n",
    "- [X]  **Part 5: Chat**\n",
    "\n",
    "\n",
    "### Theory material Checkbox\n",
    "\n",
    "- [X]  **Part 1: Understanding the Basics**\n",
    "- [X]  **Part 2: Indexing**\n",
    "- [X]  **Part 3: Semantic search with vector db**\n",
    "- [X]  **Part 4: Question and answering**\n",
    "- [X]  **Part 5: Chat**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64b282",
   "metadata": {},
   "source": [
    "## Libraries and Technologies we will use\n",
    "\n",
    "1) Pre Trained Large Language Model (LLM) like ChatGPT for vector Embedding\n",
    "2) Langchain for Supporting our model application\n",
    "3) Vector Database like Chroma\n",
    "4) Gradio\n",
    "\n",
    "\n",
    "## Generic Architecture\n",
    "\n",
    "![arch](https://ghost.hacksoft.io/content/images/2023/04/answering_questions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f6977",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "\n",
    "### Search Engines and Evolution With AI\n",
    "\n",
    "\n",
    "1. **Search Engines:** \n",
    "   - Search engines work as the librarians of the internet, scanning billions of pages to provide the most relevant results for your search queries. \n",
    "   - Traditional search engines operate primarily by scanning webpage text for matching keywords.\n",
    "\n",
    "2. **Limitations of Traditional Search Engines:**\n",
    "   - Traditional methods are limited, akin to finding a book in a library by only looking at the words on the covers without understanding the actual content of the book.\n",
    "\n",
    "3. **AI Revolution in Search Engines:**\n",
    "   - AI enables search engines to better understand the content and context of web pages and the user's intent.\n",
    "   - AI can distinguish the context in which a word is used, enhancing the relevance of search results.\n",
    "   - AI can personalize search results based on factors like previous searches and location.\n",
    "\n",
    "4. **Advanced Capabilities of AI-powered Search Engines:**\n",
    "   - AI-powered search engines can analyze and understand various data types including text, images, videos, and even voice commands.\n",
    "   - As a result, AI has transformed search engines from simple keyword-matching tools into sophisticated systems that understand and cater to the nuanced needs of users.\n",
    "   \n",
    "   \n",
    " ![search_engine](https://aeroadmin.com/articles/en/wp-content/uploads/2020/11/search-engine-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61debeee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T09:40:51.082165Z",
     "start_time": "2023-07-07T09:40:51.042885Z"
    }
   },
   "source": [
    "## Our Focus: Natural Language Search or Semantic Search\n",
    "\n",
    "Everyone knows we can use Chatgpt for searching and asking questions using Chatgpt\n",
    "\n",
    "\n",
    "![chatgpt](https://www.brookings.edu/wp-content/uploads/2023/01/shutterstock_2237655785.jpg)\n",
    "\n",
    "However it has certain limitations:\n",
    "1) It is trained on data before September 2021.\n",
    "2) We can't search and ask questions on our custom data\n",
    "\n",
    "But what if we want to augment LLM with our own data.\n",
    "\n",
    "### Retrieval augmented generation\n",
    " \n",
    "Retrieval-Augmented Generation (RAG) is a modern approach that can be used to enhance natural language search capabilities. It combines the best of retrieval-based and generative methods in NLP to answer questions or search queries.\n",
    "\n",
    "Here's a simplified explanation of how this might work:\n",
    "\n",
    "1. **Query Understanding:** Similar to traditional natural language search, the first step in RAG is understanding the user's query, which can involve Named Entity Recognition (NER), Part-of-Speech tagging (POS tagging), and other techniques to parse and interpret the query.\n",
    "\n",
    "2. **Document Retrieval:** RAG first retrieves a subset of documents from a larger corpus that are most relevant to the user's query. This retrieval step is based on a similarity measure, such as cosine similarity in the case of vectorized representations of text. The result is a shortlist of documents that are likely to contain the answer to the user's query.\n",
    "\n",
    "3. **Answer Generation:** Once the relevant documents are retrieved, a separate generative model takes the user's query and the retrieved documents as input and generates a response. The generative model can be a sequence-to-sequence model like a Transformer, which is trained to generate coherent and contextually appropriate text.\n",
    "\n",
    "\n",
    "![imng](https://cdn.thenewstack.io/media/2023/06/34141141-vector-db-llm-1024x665.png)\n",
    "\n",
    "RAG is a potent approach for natural language search, particularly for tasks that require understanding and generating language based on a large corpus of text, such as question answering or dialog systems. It combines the strengths of retrieval-based and generative models, allowing the model to access a vast amount of knowledge while generating detailed and contextually relevant responses.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e284397",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We can search on different kinds of data\n",
    "\n",
    "![search](https://redis.com/wp-content/uploads/2023/03/vector-similarity-diagram-1.svg?&auto=webp&quality=85,75&width=500)\n",
    "\n",
    "\n",
    "## Transforming Text In a Way Condusive for search\n",
    "\n",
    "Many Machine Learning algorithms and almost all Deep Learning Architectures are not capable of processing strings or plain text in their raw form. In a broad sense, they require numerical numbers as inputs to perform any sort of task, such as classification, regression, clustering, etc.\n",
    "\n",
    "Transforming text into vectors, known as vectorization, is a critical part of Natural Language Processing (NLP). This process allows us to convert human language into a format that machine learning algorithms can understand and work with. Here are a few common methods:\n",
    "\n",
    "\n",
    "\n",
    "**Bag of Words (BoW)**: This approach treats each document as an unordered bag or \"multiset\" of its words, disregarding grammar and word order but keeping the frequency of each word.\n",
    "\n",
    "![bow](https://miro.medium.com/v2/resize:fit:661/1*3K9GIOVLNu0cRvQap_KaRg.png)\n",
    "\n",
    "**Term Frequency-Inverse Document Frequency (TF-IDF)**: This method reflects how important a word is to a document in a collection or corpus. It's often used as a weighting factor in text mining and information retrieval.\n",
    "\n",
    "![tfidf](https://lh6.googleusercontent.com/GTmNOZ5DkSorxEoATI93xvrBDCCOn0XAGDav8ybPJ0hIkqlk4nimcY9P8SNleZV1Cf8vnGVAlwawdZ5Fe8kPykKRZbHVUixjSPu1BJdd9DoAdgAVr5VMwhK2oSkXpyDFXunuON-l)\n",
    "\n",
    "**Word Embeddings**: These are dense vector representations in which similar words have similar vectors in the vector space. Word2Vec and GloVe are two popular methods of creating word embeddings. Word embeddings capture more nuanced semantic meanings and relationships between words compared to BoW and TF-IDF.\n",
    "\n",
    "![vectors](https://www.researchgate.net/publication/340825443/figure/fig6/AS:882927785238529@1587517796128/Word-embeddings-map-words-in-a-corpus-of-text-to-vector-space-Linear-combinations-of.png)\n",
    "\n",
    "\n",
    "**Word2Vec**\n",
    "- It is a shallow neural network model that generates word embeddings â€“ vectors that represent words in a high-dimensional space.\n",
    "- Word2Vec models, like Skip-gram and Continuous Bag of Words (CBOW), are trained to reconstruct the linguistic context of words.\n",
    "- Word2Vec can capture some semantic and syntactic relationships between words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1378b",
   "metadata": {},
   "source": [
    "## Transformers And LLMs\n",
    "\n",
    "### Limitations of Word2Vec\n",
    "1) Word2Vec does not consider the order of words (e.g., \"cat chases dog\" and \"dog chases cat\" are treated the same).\n",
    "2) Word2Vec generates a single vector representation for each word, regardless of the context (e.g., \"bank\" as a river bank and \"bank\" as a financial institution are treated the same).\n",
    "\n",
    "\n",
    "### Transitioning into Transformers\n",
    "\n",
    "To overcome these limitations, researchers developed new techniques and models that could understand context better.\n",
    "\n",
    "**Contextual Word Embeddings (ELMo, etc.)**: ELMo (Embeddings from Language Models) assigns embeddings to words based on their context, addressing the polysemy issue present in Word2Vec.\n",
    "\n",
    "**Transformers**: The Transformer model, introduced in the paper \"Attention is All You Need,\" revolutionized NLP. It's based on the idea of self-attention, allowing the model to weigh and understand the impact of each word on others in a sentence.\n",
    "\n",
    "The transformer model architecture underlies models like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pretrained Transformer). Unlike Word2Vec, these models provide context-aware representations by considering words in their specific context.\n",
    "\n",
    "**BERT** uses bidirectional training of Transformers, meaning it looks at the context from both left and right sides (words before and after the target word).\n",
    "\n",
    "**GPT** uses a transformer decoder and is trained in a unidirectional manner. It has been used extensively for tasks that require the generation of text.\n",
    "\n",
    "In summary, while we started with Word2Vec creating context-free embeddings, we've moved toward Transformer-based models that provide powerful context-dependent representations, leading to significant improvements in various NLP tasks.\n",
    "\n",
    "\n",
    "### How are LLMs related to transformers\n",
    "\n",
    "\n",
    "Large Language Models (LLMs) such as GPT-3 by OpenAI, BERT from Google, and RoBERTa from Facebook AI, all have their roots in the Transformer architecture and use vector embeddings as a fundamental part of their operation.\n",
    "\n",
    "* These models use the attention mechanism to generate context-aware word embeddings, superior to traditional embeddings generated by Word2Vec or GloVe.\n",
    "* They are trained on extensive amounts of text data and can understand and generate human-like text.\n",
    "* LLMs have achieved state-of-the-art performance on a wide range of NLP tasks, such as text classification, question answering, and named entity recognition\n",
    "\n",
    "\n",
    "![embedding](https://miro.medium.com/v2/resize:fit:1324/1*3XZgoCaZg1e9ySfXPTtfQg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3526d",
   "metadata": {},
   "source": [
    "## Vector Databases\n",
    "\n",
    "![db](https://miro.medium.com/v2/resize:fit:1400/1*VXrN-lBukxTqQVBrlS1lZg.png)\n",
    "\n",
    "Vector databases, also known as vector search engines or similarity search engines, play a crucial role in managing and leveraging high-dimensional vector data produced by Machine Learning (ML) models, including the Large Language Models (LLMs) in NLP tasks. Here's how they can be helpful:\n",
    "\n",
    "1. **Efficient Similarity Search**: Vector databases are designed to enable fast and efficient similarity search in high-dimensional vector spaces. They can help find the vectors that are most similar to a given vector, which is a common requirement in NLP tasks.\n",
    "\n",
    "2. **Scalable Storage and Retrieval**: Vector databases provide a scalable solution for storing and retrieving large amounts of high-dimensional vector data.\n",
    "\n",
    "3. **Integration with ML Workflows**: Vector databases can be easily integrated into ML workflows. They can serve as a bridge between the offline training of models and the online serving of results.\n",
    "\n",
    "4. **Use Cases in NLP**: In the context of NLP and language models, vector databases can be used to store and retrieve word or sentence embeddings. They can be used in tasks like semantic search (finding documents with similar meanings), recommendation systems (finding similar items or content), and more.\n",
    "\n",
    "5. **Real-time Applications**: With their ability to provide quick similarity search results, vector databases can support real-time applications such as chatbots, personalized recommendations, and more.\n",
    "\n",
    "In summary, vector databases help to store, manage, and retrieve the high-dimensional vector data produced by models like transformers, thus enabling the effective application of these models in various NLP tasks.\n",
    "\n",
    "\n",
    "![vectordb](https://cdn.sanity.io/images/vr8gru94/production/e88ebbacb848b09e477d11eedf4209d10ea4ac0a-1399x537.png)\n",
    "\n",
    "\n",
    "### When to use a vector database\n",
    "\n",
    "Using a vector database as opposed to a simple file for storing and retrieving vector data becomes essential in various situations. Here are some scenarios when you would want to opt for a vector database:\n",
    "\n",
    "1. **Large-scale Data**: If you're dealing with large-scale vector data, simply reading from and writing to files can be inefficient. A vector database is designed to handle such large amounts of data efficiently and quickly.\n",
    "\n",
    "2. **Efficient Searching**: If you need to perform similarity search queries on the vector data, a vector database provides sophisticated indexing mechanisms to allow efficient nearest-neighbor search, which would be highly inefficient with plain files.\n",
    "\n",
    "3. **Concurrency and Real-time Access**: If you need concurrent access to your vector data or if your application requires real-time data access, a vector database is a better fit as it supports these requirements out of the box. File-based systems, on the other hand, may struggle with concurrent accesses and real-time data retrieval.\n",
    "\n",
    "4. **Data Persistence and Reliability**: If you need your data to be reliably stored and persist across sessions or if you want built-in backup and restore capabilities, a vector database is a much safer bet than simple file storage.\n",
    "\n",
    "5. **Scalability and Distributed Computing**: Vector databases are built to work in distributed computing environments and can easily scale up or down based on the needs of your application. This is not typically possible with file-based storage without significant manual intervention.\n",
    "\n",
    "However, if your use case involves small-scale data, infrequent access, or does not require efficient search capabilities, a simple file-based storage might suffice. The choice between a vector database and a file really depends on the specifics of your use case and the scale and complexity of your data.\n",
    "\n",
    "\n",
    "### How does it work\n",
    "\n",
    "![vectordb](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83af13e6-8e84-4e37-84e9-244f3aa3e95b_2071x2470.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f591a5",
   "metadata": {},
   "source": [
    "### Commercially available Vector Databases\n",
    "\n",
    "1) Milvus\n",
    "2) Kinetica\n",
    "3) Chroma\n",
    "4) Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb888ac7",
   "metadata": {},
   "source": [
    "# Hands On Coding\n",
    "\n",
    "## Dependencies Installation and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "39fcfbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T08:04:34.185617Z",
     "start_time": "2023-07-18T08:04:28.027940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (0.0.190)\n",
      "Requirement already satisfied: openai in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: chromadb in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (0.3.26)\n",
      "Requirement already satisfied: kaggle in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (1.5.15)\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: datasets in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (2.13.1)\n",
      "Requirement already satisfied: gradio in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (3.36.1)\n",
      "Requirement already satisfied: elasticsearch in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (8.8.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (2.0.17)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (1.25.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (1.10.10)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (2.0.3)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (0.6.4)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (0.8.1)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (0.99.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (4.7.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (0.13.3)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from chromadb) (7.3.1)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from kaggle) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (4.30.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sentence_transformers) (0.16.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from datasets) (23.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiofiles in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: ffmpy in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: gradio-client>=0.2.7 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (0.2.7)\n",
      "Requirement already satisfied: httpx in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: orjson in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydub in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pygments>=2.12.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: semantic-version in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from elasticsearch) (8.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: pytz in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: zstandard in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "Requirement already satisfied: lz4 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.3)\n",
      "Requirement already satisfied: sympy in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: networkx in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click>=7.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from httpx->gradio) (0.17.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from matplotlib->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from matplotlib->gradio) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from matplotlib->gradio) (3.1.0)\n",
      "Requirement already satisfied: joblib in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai chromadb kaggle sentence_transformers datasets gradio elasticsearch tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3134955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:02.338654Z",
     "start_time": "2023-07-18T07:52:02.298450Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.isfile(\"database.sqlite\"):\n",
    "    os.system(\"kaggle datasets download benhamner/nips-papersv\")\n",
    "    os.system(\"unzip -o nips-papers.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26bdddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:10.267018Z",
     "start_time": "2023-07-18T07:52:02.350926Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "import sqlite3\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b4e167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:14.133216Z",
     "start_time": "2023-07-18T07:52:10.273131Z"
    }
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"database.sqlite\")\n",
    "\n",
    "sql= \"\"\"WITH paper_author_list AS (\n",
    "    SELECT papers.id AS paper_id, Group_concat(authors.name) AS author_list\n",
    "    FROM papers\n",
    "    JOIN paper_authors ON papers.id = paper_authors.paper_id\n",
    "    JOIN authors ON paper_authors.author_id = authors.id\n",
    "    GROUP BY paper_id\n",
    ")\n",
    "SELECT papers.id AS paper_id, papers.year, papers.title, papers.abstract, papers.paper_text, paper_author_list.author_list AS authors\n",
    "FROM papers\n",
    "JOIN paper_author_list ON papers.id = paper_author_list.paper_id\n",
    "WHERE abstract NOT LIKE '%Abstract Missing%'\n",
    "\n",
    "\"\"\";\n",
    "\n",
    "papers_df = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "481493fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:14.257711Z",
     "start_time": "2023-07-18T07:52:14.136272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Algorithms for Non-negative Matrix Factorization</td>\n",
       "      <td>Non-negative matrix factorization (NMF) has pr...</td>\n",
       "      <td>Algorithms for Non-negative Matrix\\nFactorizat...</td>\n",
       "      <td>Daniel D. Lee,H. Sebastian Seung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Characterizing Neural Gain Control using Spike...</td>\n",
       "      <td>Spike-triggered averaging techniques are effec...</td>\n",
       "      <td>Characterizing neural gain control using\\nspik...</td>\n",
       "      <td>Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Competition Adds Complexity</td>\n",
       "      <td>It is known that determinining whether a DEC-P...</td>\n",
       "      <td>Competition adds complexity\\n\\nJudy Goldsmith\\...</td>\n",
       "      <td>Judy Goldsmith,Martin Mundhenk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>We present the first truly polynomial algorith...</td>\n",
       "      <td>Efficient Principled Learning of Thin Junction...</td>\n",
       "      <td>Anton Chechetka,Carlos Guestrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning</td>\n",
       "      <td>Semi-supervised inductive learning concerns ho...</td>\n",
       "      <td>Regularized Boost for Semi-Supervised Learning...</td>\n",
       "      <td>Ke Chen,Shihai Wang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  year                                              title  \\\n",
       "0      1861  2000   Algorithms for Non-negative Matrix Factorization   \n",
       "1      1975  2001  Characterizing Neural Gain Control using Spike...   \n",
       "2      3163  2007                        Competition Adds Complexity   \n",
       "3      3164  2007  Efficient Principled Learning of Thin Junction...   \n",
       "4      3167  2007     Regularized Boost for Semi-Supervised Learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Non-negative matrix factorization (NMF) has pr...   \n",
       "1  Spike-triggered averaging techniques are effec...   \n",
       "2  It is known that determinining whether a DEC-P...   \n",
       "3  We present the first truly polynomial algorith...   \n",
       "4  Semi-supervised inductive learning concerns ho...   \n",
       "\n",
       "                                          paper_text  \\\n",
       "0  Algorithms for Non-negative Matrix\\nFactorizat...   \n",
       "1  Characterizing neural gain control using\\nspik...   \n",
       "2  Competition adds complexity\\n\\nJudy Goldsmith\\...   \n",
       "3  Efficient Principled Learning of Thin Junction...   \n",
       "4  Regularized Boost for Semi-Supervised Learning...   \n",
       "\n",
       "                                             authors  \n",
       "0                   Daniel D. Lee,H. Sebastian Seung  \n",
       "1  Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...  \n",
       "2                     Judy Goldsmith,Martin Mundhenk  \n",
       "3                    Anton Chechetka,Carlos Guestrin  \n",
       "4                                Ke Chen,Shihai Wang  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58712470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:14.268668Z",
     "start_time": "2023-07-18T07:52:14.262146Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_text(papers_df, column):\n",
    "    \n",
    "    # Load the regular expression library\n",
    "    import re\n",
    "    preprocessed_column = f\"{column}_processed\"\n",
    "\n",
    "    # Print the titles of the first rows \n",
    "    print(papers_df[column].head())\n",
    "\n",
    "    # remove punctuations\n",
    "    #papers_df[preprocessed_column] = papers_df[column].map(lambda x: re.sub('[,!?]', '', x))\n",
    "    \n",
    "     # remove carriage return and end of line\n",
    "    papers_df[preprocessed_column] = papers_df[column].map(lambda x: re.sub('[\\r\\n]', ' ', x))\n",
    "    \n",
    "     # remove double spaces\n",
    "    papers_df[preprocessed_column] = papers_df[preprocessed_column].map(lambda x: re.sub('  ', ' ', x))\n",
    "\n",
    "    \n",
    "    # remove para continuation\n",
    "    papers_df[preprocessed_column] = papers_df[preprocessed_column].map(lambda x: re.sub('- ', '', x))\n",
    "\n",
    "    # Convert the titles to lowercase\n",
    "    papers_df[preprocessed_column] = papers_df[preprocessed_column].map(lambda x: x.lower())\n",
    "    return papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1362e65f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:19.934833Z",
     "start_time": "2023-07-18T07:52:14.273794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Algorithms for Non-negative Matrix Factorization\n",
      "1    Characterizing Neural Gain Control using Spike...\n",
      "2                          Competition Adds Complexity\n",
      "3    Efficient Principled Learning of Thin Junction...\n",
      "4       Regularized Boost for Semi-Supervised Learning\n",
      "Name: title, dtype: object\n",
      "0    Non-negative matrix factorization (NMF) has pr...\n",
      "1    Spike-triggered averaging techniques are effec...\n",
      "2    It is known that determinining whether a DEC-P...\n",
      "3    We present the first truly polynomial algorith...\n",
      "4    Semi-supervised inductive learning concerns ho...\n",
      "Name: abstract, dtype: object\n",
      "0    Algorithms for Non-negative Matrix\\nFactorizat...\n",
      "1    Characterizing neural gain control using\\nspik...\n",
      "2    Competition adds complexity\\n\\nJudy Goldsmith\\...\n",
      "3    Efficient Principled Learning of Thin Junction...\n",
      "4    Regularized Boost for Semi-Supervised Learning...\n",
      "Name: paper_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_columns = [\"title\", \"abstract\", \"paper_text\"]\n",
    "for column in text_columns:\n",
    "    pre_process_text(papers_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7b97d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:19.978245Z",
     "start_time": "2023-07-18T07:52:19.938393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.abstract_processed[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d05f13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:20.016350Z",
     "start_time": "2023-07-18T07:52:19.985408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>abstract_processed</th>\n",
       "      <th>paper_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Daniel D. Lee,H. Sebastian Seung</td>\n",
       "      <td>algorithms for non-negative matrix factorization</td>\n",
       "      <td>non-negative matrix factorization (nmf) has pr...</td>\n",
       "      <td>algorithms for non-negative matrix factorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "      <td>spike-triggered averaging techniques are effec...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Judy Goldsmith,Martin Mundhenk</td>\n",
       "      <td>competition adds complexity</td>\n",
       "      <td>it is known that determinining whether a dec-p...</td>\n",
       "      <td>competition adds complexity judy goldsmith dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Anton Chechetka,Carlos Guestrin</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "      <td>we present the first truly polynomial algorith...</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ke Chen,Shihai Wang</td>\n",
       "      <td>regularized boost for semi-supervised learning</td>\n",
       "      <td>semi-supervised inductive learning concerns ho...</td>\n",
       "      <td>regularized boost for semi-supervised learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  year                                            authors  \\\n",
       "0      1861  2000                   Daniel D. Lee,H. Sebastian Seung   \n",
       "1      1975  2001  Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...   \n",
       "2      3163  2007                     Judy Goldsmith,Martin Mundhenk   \n",
       "3      3164  2007                    Anton Chechetka,Carlos Guestrin   \n",
       "4      3167  2007                                Ke Chen,Shihai Wang   \n",
       "\n",
       "                                     title_processed  \\\n",
       "0   algorithms for non-negative matrix factorization   \n",
       "1  characterizing neural gain control using spike...   \n",
       "2                        competition adds complexity   \n",
       "3  efficient principled learning of thin junction...   \n",
       "4     regularized boost for semi-supervised learning   \n",
       "\n",
       "                                  abstract_processed  \\\n",
       "0  non-negative matrix factorization (nmf) has pr...   \n",
       "1  spike-triggered averaging techniques are effec...   \n",
       "2  it is known that determinining whether a dec-p...   \n",
       "3  we present the first truly polynomial algorith...   \n",
       "4  semi-supervised inductive learning concerns ho...   \n",
       "\n",
       "                                paper_text_processed  \n",
       "0  algorithms for non-negative matrix factorizati...  \n",
       "1  characterizing neural gain control using spike...  \n",
       "2  competition adds complexity judy goldsmith dep...  \n",
       "3  efficient principled learning of thin junction...  \n",
       "4  regularized boost for semi-supervised learning...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df = papers_df.drop([\"title\", \"abstract\", \"paper_text\"], axis=1)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea936a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:20.038904Z",
     "start_time": "2023-07-18T07:52:20.031035Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_df = papers_df.rename(columns={'title_processed':'title', 'abstract_processed': 'abstract', 'paper_text_processed': 'paper_text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdac785d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:20.057240Z",
     "start_time": "2023-07-18T07:52:20.042524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1861</td>\n",
       "      <td>2000</td>\n",
       "      <td>Daniel D. Lee,H. Sebastian Seung</td>\n",
       "      <td>algorithms for non-negative matrix factorization</td>\n",
       "      <td>non-negative matrix factorization (nmf) has pr...</td>\n",
       "      <td>algorithms for non-negative matrix factorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>2001</td>\n",
       "      <td>Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "      <td>spike-triggered averaging techniques are effec...</td>\n",
       "      <td>characterizing neural gain control using spike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3163</td>\n",
       "      <td>2007</td>\n",
       "      <td>Judy Goldsmith,Martin Mundhenk</td>\n",
       "      <td>competition adds complexity</td>\n",
       "      <td>it is known that determinining whether a dec-p...</td>\n",
       "      <td>competition adds complexity judy goldsmith dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3164</td>\n",
       "      <td>2007</td>\n",
       "      <td>Anton Chechetka,Carlos Guestrin</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "      <td>we present the first truly polynomial algorith...</td>\n",
       "      <td>efficient principled learning of thin junction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167</td>\n",
       "      <td>2007</td>\n",
       "      <td>Ke Chen,Shihai Wang</td>\n",
       "      <td>regularized boost for semi-supervised learning</td>\n",
       "      <td>semi-supervised inductive learning concerns ho...</td>\n",
       "      <td>regularized boost for semi-supervised learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id  year                                            authors  \\\n",
       "0      1861  2000                   Daniel D. Lee,H. Sebastian Seung   \n",
       "1      1975  2001  Odelia Schwartz,E.J. Chichilnisky,Eero P. Simo...   \n",
       "2      3163  2007                     Judy Goldsmith,Martin Mundhenk   \n",
       "3      3164  2007                    Anton Chechetka,Carlos Guestrin   \n",
       "4      3167  2007                                Ke Chen,Shihai Wang   \n",
       "\n",
       "                                               title  \\\n",
       "0   algorithms for non-negative matrix factorization   \n",
       "1  characterizing neural gain control using spike...   \n",
       "2                        competition adds complexity   \n",
       "3  efficient principled learning of thin junction...   \n",
       "4     regularized boost for semi-supervised learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  non-negative matrix factorization (nmf) has pr...   \n",
       "1  spike-triggered averaging techniques are effec...   \n",
       "2  it is known that determinining whether a dec-p...   \n",
       "3  we present the first truly polynomial algorith...   \n",
       "4  semi-supervised inductive learning concerns ho...   \n",
       "\n",
       "                                          paper_text  \n",
       "0  algorithms for non-negative matrix factorizati...  \n",
       "1  characterizing neural gain control using spike...  \n",
       "2  competition adds complexity judy goldsmith dep...  \n",
       "3  efficient principled learning of thin junction...  \n",
       "4  regularized boost for semi-supervised learning...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861cf4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:20.067801Z",
     "start_time": "2023-07-18T07:52:20.061710Z"
    }
   },
   "outputs": [],
   "source": [
    "papers_df = papers_df.drop([\"paper_text\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9deb61f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:20.075854Z",
     "start_time": "2023-07-18T07:52:20.071188Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../secret/openai\") as f:\n",
    "    openai_secret = f.read().strip()\n",
    "    \n",
    "# PDF_FILE = \"../data/GenericEmailMarketting/merged_file.pdf\"\n",
    "\n",
    "# use import getpass instead\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "212a593a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:20.246827Z",
     "start_time": "2023-07-18T07:52:20.079771Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm.openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21d7ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:21.705201Z",
     "start_time": "2023-07-18T07:52:20.251429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "989397ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:22.787028Z",
     "start_time": "2023-07-18T07:52:21.715527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nThe current Prime Minister of the United Kingdom is Boris Johnson.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Who is the current prime minister of Britain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7921616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:22.802102Z",
     "start_time": "2023-07-18T07:52:22.795185Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "def get_openai_embedding(text):\n",
    "   text_rep = text.replace(\"\\n\", \" \")\n",
    "   return embeddings_model.embed_documents([text_rep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a49a512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:22.812135Z",
     "start_time": "2023-07-18T07:52:22.805366Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence1 = \"i like summer\"\n",
    "sentence2 = \"Brocholi on pizza is probably not a good idea\"\n",
    "sentence3 = \"I love the warm weather outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f66b98be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:24.092131Z",
     "start_time": "2023-07-18T07:52:22.820355Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding1 = embeddings_model.embed_query(sentence1)\n",
    "embedding2 = embeddings_model.embed_query(sentence2)\n",
    "embedding3 = embeddings_model.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "094e1686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:24.104759Z",
     "start_time": "2023-07-18T07:52:24.095599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7065412380498463\n",
      "0.7130862462871117\n",
      "0.8759279450458031\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(embedding1, embedding2))\n",
    "print(np.dot(embedding2, embedding3))\n",
    "print(np.dot(embedding1, embedding3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606365d1",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dc5321d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:24.134736Z",
     "start_time": "2023-07-18T07:52:24.116641Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efbdd543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:24.251026Z",
     "start_time": "2023-07-18T07:52:24.200764Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataFrameLoader(papers_df, page_content_column=\"abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d09697be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.226301Z",
     "start_time": "2023-07-18T07:52:24.255393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use lazy load for larger table, which won't read the full table into memory \n",
    "page = loader.load()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b063e7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.237405Z",
     "start_time": "2023-07-18T07:52:25.229679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92c593b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.377019Z",
     "start_time": "2023-07-18T07:52:25.281795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_id': 1861,\n",
       " 'year': 2000,\n",
       " 'authors': 'Daniel D. Lee,H. Sebastian Seung',\n",
       " 'title': 'algorithms for non-negative matrix factorization'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "620c0386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.389424Z",
     "start_time": "2023-07-18T07:52:25.381689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.schema.Document"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993d2d2",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4c56d3",
   "metadata": {},
   "source": [
    "### Why do we need to split the data\n",
    "1) Chatgpt and LLM have limits\n",
    "\n",
    "![limits](https://miro.medium.com/v2/resize:fit:0/1*ihkkB2g7j9CMHBfvJtfLKw.png)\n",
    "\n",
    "2) To allow for efficient search for vector spaces\n",
    "\n",
    "![embeddings](https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676309873/mirroredImages/pHPmMGEMYefk9jLeh/uvqfemlxskwrikptzeaq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aa73477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.399857Z",
     "start_time": "2023-07-18T07:52:25.394331Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6dfe267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.426952Z",
     "start_time": "2023-07-18T07:52:25.421511Z"
    }
   },
   "outputs": [],
   "source": [
    "r_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "    chunk_size = 26,\n",
    "    chunk_overlap  = 4,\n",
    "    length_function = len,\n",
    "    #seperators=['\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 26,\n",
    "    chunk_overlap  = 4,\n",
    "    length_function = len,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90acef87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.437612Z",
     "start_time": "2023-07-18T07:52:25.431676Z"
    }
   },
   "outputs": [],
   "source": [
    "text_a2z = 'abcdefghijklmnopqrstuvwxyz'\n",
    "text_a2z_plus = 'abcdefghijklmnopqrstuvwxyz 12345678'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74f2a024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.451196Z",
     "start_time": "2023-07-18T07:52:25.442881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(text_a2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25a2e5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.463587Z",
     "start_time": "2023-07-18T07:52:25.455801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', '12345678']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(text_a2z_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "491d7b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.477304Z",
     "start_time": "2023-07-18T07:52:25.467521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text_a2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e07b0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.496937Z",
     "start_time": "2023-07-18T07:52:25.484327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz 12345678']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text_a2z_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1f09e",
   "metadata": {},
   "source": [
    "The issue is Character text splitter splits only on new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89eebdef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.532045Z",
     "start_time": "2023-07-18T07:52:25.523062Z"
    }
   },
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 26,\n",
    "    chunk_overlap  = 4,\n",
    "    length_function = len,\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "012f4002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.554556Z",
     "start_time": "2023-07-18T07:52:25.542200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', '12345678']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text_a2z_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d14ea5dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.568553Z",
     "start_time": "2023-07-18T07:52:25.559868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = page.page_content\n",
    "\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7ba264c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.585100Z",
     "start_time": "2023-07-18T07:52:25.572451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix',\n",
       " 'factorization (nmf) has',\n",
       " 'has previously been shown',\n",
       " 'to  be a useful',\n",
       " 'decomposition for',\n",
       " 'for multivariate data.',\n",
       " 'two different multi',\n",
       " 'plicative algorithms for',\n",
       " 'for nmf are analyzed.',\n",
       " 'they differ only slightly',\n",
       " 'in  the multiplicative',\n",
       " 'factor used in the update',\n",
       " 'rules. one algorithm can',\n",
       " 'can be  shown to minimize',\n",
       " 'the conventional least',\n",
       " 'squares error while the',\n",
       " 'the other  minimizes the',\n",
       " 'the generalized',\n",
       " 'kullback-leibler',\n",
       " 'divergence. the monotonic',\n",
       " 'convergence of both',\n",
       " 'algorithms can be proven',\n",
       " 'using an auxiliary func',\n",
       " 'tion analogous to that',\n",
       " 'used for proving',\n",
       " 'convergence of the',\n",
       " 'the expectation',\n",
       " 'maximization algorithm.',\n",
       " 'the algorithms can also',\n",
       " 'be interpreted as diag',\n",
       " 'onally rescaled gradient',\n",
       " 'descent, where the',\n",
       " 'the rescaling factor is',\n",
       " 'is optimally  chosen to',\n",
       " 'to ensure convergence.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "844da99d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.600512Z",
     "start_time": "2023-07-18T07:52:25.590891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix',\n",
       " 'factorization (nmf) has',\n",
       " 'has previously been shown',\n",
       " 'to be a useful',\n",
       " 'decomposition for',\n",
       " 'for multivariate data. two',\n",
       " 'two different multi',\n",
       " 'plicative algorithms for',\n",
       " 'for nmf are analyzed. they',\n",
       " 'they differ only slightly',\n",
       " 'in the multiplicative',\n",
       " 'factor used in the update',\n",
       " 'rules. one algorithm can',\n",
       " 'can be shown to minimize',\n",
       " 'the conventional least',\n",
       " 'squares error while the',\n",
       " 'the other minimizes the',\n",
       " 'the generalized',\n",
       " 'kullback-leibler',\n",
       " 'divergence. the monotonic',\n",
       " 'convergence of both',\n",
       " 'both algorithms can be',\n",
       " 'be proven using an',\n",
       " 'an auxiliary func tion',\n",
       " 'tion analogous to that',\n",
       " 'that used for proving',\n",
       " 'convergence of the',\n",
       " 'the expectation',\n",
       " 'maximization algorithm.',\n",
       " 'the algorithms can also be',\n",
       " 'be interpreted as diag',\n",
       " 'diag onally rescaled',\n",
       " 'gradient descent, where',\n",
       " 'the rescaling factor is',\n",
       " 'is optimally chosen to',\n",
       " 'to ensure convergence.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6374d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.611820Z",
     "start_time": "2023-07-18T07:52:25.605077Z"
    }
   },
   "outputs": [],
   "source": [
    "r_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "   \n",
    "    length_function = len,\n",
    "    separators=['\\n\\n', \"\\n\", \" \", \"\"],\n",
    "     chunk_size = 150,\n",
    "    chunk_overlap  = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5770388e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.669646Z",
     "start_time": "2023-07-18T07:52:25.620922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative',\n",
       " 'algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to',\n",
       " 'minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of',\n",
       " 'both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm.',\n",
       " 'the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure',\n",
       " 'convergence.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7177ee16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.681613Z",
     "start_time": "2023-07-18T07:52:25.674715Z"
    }
   },
   "outputs": [],
   "source": [
    "r_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "    length_function = len,\n",
    "    separators=['\\n\\n', \"\\n\", \" \",\"\\.\", \"\"],\n",
    "     chunk_size = 1000,\n",
    "    chunk_overlap  = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b438550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.695794Z",
     "start_time": "2023-07-18T07:52:25.687607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0b58bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.710695Z",
     "start_time": "2023-07-18T07:52:25.701921Z"
    }
   },
   "outputs": [],
   "source": [
    "# what if we want to split by sentences\n",
    "# regex with look behind\n",
    "sentence_spltter = RecursiveCharacterTextSplitter( # Set a really small chunk size, just to show.\n",
    "    length_function = len,\n",
    "    separators=[\"(?<=\\.)\"],\n",
    "     chunk_size = 150,\n",
    "    chunk_overlap  = 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b77495da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.726080Z",
     "start_time": "2023-07-18T07:52:25.716976Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data.',\n",
       " 'two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules.',\n",
       " 'one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence.',\n",
       " ' the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm.',\n",
       " ' the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_spltter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34f6472a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:25.735335Z",
     "start_time": "2023-07-18T07:52:25.730624Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b8a069a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:32.905174Z",
     "start_time": "2023-07-18T07:52:25.741042Z"
    }
   },
   "outputs": [],
   "source": [
    "token_text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f7c5c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:32.995200Z",
     "start_time": "2023-07-18T07:52:32.914216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc',\n",
       " 'def',\n",
       " 'gh',\n",
       " 'ij',\n",
       " 'kl',\n",
       " 'mn',\n",
       " 'op',\n",
       " 'q',\n",
       " 'r',\n",
       " 'st',\n",
       " 'uv',\n",
       " 'w',\n",
       " 'xy',\n",
       " 'z']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text_splitter.split_text(text_a2z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef5a7247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:33.031868Z",
     "start_time": "2023-07-18T07:52:33.008784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['non',\n",
       " '-',\n",
       " 'negative',\n",
       " ' matrix',\n",
       " ' factor',\n",
       " 'ization',\n",
       " ' (',\n",
       " 'nm',\n",
       " 'f',\n",
       " ')',\n",
       " ' has',\n",
       " ' previously',\n",
       " ' been',\n",
       " ' shown',\n",
       " ' to',\n",
       " ' ',\n",
       " ' be',\n",
       " ' a',\n",
       " ' useful',\n",
       " ' decom',\n",
       " 'position',\n",
       " ' for',\n",
       " ' mult',\n",
       " 'ivariate',\n",
       " ' data',\n",
       " '.',\n",
       " ' two',\n",
       " ' different',\n",
       " ' multi',\n",
       " ' pl',\n",
       " 'icative',\n",
       " ' algorithms',\n",
       " ' for',\n",
       " ' nm',\n",
       " 'f',\n",
       " ' are',\n",
       " ' analyzed',\n",
       " '.',\n",
       " ' they',\n",
       " ' differ',\n",
       " ' only',\n",
       " ' slightly',\n",
       " ' in',\n",
       " ' ',\n",
       " ' the',\n",
       " ' multipl',\n",
       " 'icative',\n",
       " ' factor',\n",
       " ' used',\n",
       " ' in',\n",
       " ' the',\n",
       " ' update',\n",
       " ' rules',\n",
       " '.',\n",
       " ' one',\n",
       " ' algorithm',\n",
       " ' can',\n",
       " ' be',\n",
       " ' ',\n",
       " ' shown',\n",
       " ' to',\n",
       " ' minimize',\n",
       " ' the',\n",
       " ' conventional',\n",
       " ' least',\n",
       " ' squares',\n",
       " ' error',\n",
       " ' while',\n",
       " ' the',\n",
       " ' other',\n",
       " ' ',\n",
       " ' minim',\n",
       " 'izes',\n",
       " ' the',\n",
       " ' generalized',\n",
       " ' k',\n",
       " 'ull',\n",
       " 'back',\n",
       " '-',\n",
       " 'le',\n",
       " 'ib',\n",
       " 'ler',\n",
       " ' divergence',\n",
       " '.',\n",
       " ' the',\n",
       " ' mon',\n",
       " 'ot',\n",
       " 'onic',\n",
       " ' ',\n",
       " ' convergence',\n",
       " ' of',\n",
       " ' both',\n",
       " ' algorithms',\n",
       " ' can',\n",
       " ' be',\n",
       " ' proven',\n",
       " ' using',\n",
       " ' an',\n",
       " ' auxiliary',\n",
       " ' func',\n",
       " ' tion',\n",
       " ' analogous',\n",
       " ' to',\n",
       " ' that',\n",
       " ' used',\n",
       " ' for',\n",
       " ' proving',\n",
       " ' convergence',\n",
       " ' of',\n",
       " ' the',\n",
       " ' expectation',\n",
       " ' maxim',\n",
       " 'ization',\n",
       " ' algorithm',\n",
       " '.',\n",
       " ' the',\n",
       " ' algorithms',\n",
       " ' can',\n",
       " ' also',\n",
       " ' be',\n",
       " ' interpreted',\n",
       " ' as',\n",
       " ' di',\n",
       " 'ag',\n",
       " ' on',\n",
       " 'ally',\n",
       " ' resc',\n",
       " 'aled',\n",
       " ' gradient',\n",
       " ' descent',\n",
       " ',',\n",
       " ' where',\n",
       " ' the',\n",
       " ' resc',\n",
       " 'aling',\n",
       " ' factor',\n",
       " ' is',\n",
       " ' optim',\n",
       " 'ally',\n",
       " ' ',\n",
       " ' chosen',\n",
       " ' to',\n",
       " ' ensure',\n",
       " ' convergence',\n",
       " '.',\n",
       " ' ']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text_splitter.split_text(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abbbe69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:35.294137Z",
     "start_time": "2023-07-18T07:52:33.051647Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b279b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:35.323532Z",
     "start_time": "2023-07-18T07:52:35.303224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3921"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb678030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:35.355792Z",
     "start_time": "2023-07-18T07:52:35.332896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data. two different multi plicative algorithms for nmf are analyzed. they differ only slightly in  the multiplicative factor used in the update rules. one algorithm can be  shown to minimize the conventional least squares error while the other  minimizes the generalized kullback-leibler divergence. the monotonic  convergence of both algorithms can be proven using an auxiliary func tion analogous to that used for proving convergence of the expectation maximization algorithm. the algorithms can also be interpreted as diag onally rescaled gradient descent, where the rescaling factor is optimally  chosen to ensure convergence. ', metadata={'paper_id': 1861, 'year': 2000, 'authors': 'Daniel D. Lee,H. Sebastian Seung', 'title': 'algorithms for non-negative matrix factorization'})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b7e1dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:35.377647Z",
     "start_time": "2023-07-18T07:52:35.368525Z"
    }
   },
   "outputs": [],
   "source": [
    "# For simplicity we will use sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f53ea8c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:37.275894Z",
     "start_time": "2023-07-18T07:52:35.387940Z"
    }
   },
   "outputs": [],
   "source": [
    "splits = sentence_spltter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6ee0239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:37.383150Z",
     "start_time": "2023-07-18T07:52:37.283243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='non-negative matrix factorization (nmf) has previously been shown to  be a useful decomposition for multivariate data.', metadata={'paper_id': 1861, 'year': 2000, 'authors': 'Daniel D. Lee,H. Sebastian Seung', 'title': 'algorithms for non-negative matrix factorization'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1d15f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:42.532354Z",
     "start_time": "2023-07-18T07:52:37.391946Z"
    }
   },
   "outputs": [],
   "source": [
    "random_splits = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bde27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b511cfa7",
   "metadata": {},
   "source": [
    "## Indexing data in Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9565318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:42.656235Z",
     "start_time": "2023-07-18T07:52:42.543928Z"
    }
   },
   "outputs": [],
   "source": [
    "persist_directory_random_split_gpt = 'data/chroma/random_split/gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65b81159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:52:43.019855Z",
     "start_time": "2023-07-18T07:52:42.667967Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf ./data/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "069b47e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:12.862521Z",
     "start_time": "2023-07-18T07:52:43.031569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 8.88 s, total: 2min 16s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectordb_gpt = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory_random_split_gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54ac24f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:12.888826Z",
     "start_time": "2023-07-18T07:57:12.878131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25143\n"
     ]
    }
   ],
   "source": [
    "print(vectordb_gpt._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abd9068c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:24.954323Z",
     "start_time": "2023-07-18T07:57:12.895452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4e474a20ff456cb5ce1366a20248cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectordb_gpt.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d22025b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:25.179552Z",
     "start_time": "2023-07-18T07:57:24.957457Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import ElasticVectorSearch\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticKnnSearch\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "elastic = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "index_name = \"test_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7a96406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.689896Z",
     "start_time": "2023-07-18T07:57:25.184237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/q4kkg14x6c9bg29754hkb_yr0000gn/T/ipykernel_7035/2402150112.py:1: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  elastic.delete_by_query(index=[index_name], body={\"query\": {\"match_all\": {}}})\n"
     ]
    },
    {
     "ename": "ConnectionTimeout",
     "evalue": "Connection timed out",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionTimeout\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43melastic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete_by_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mindex_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mquery\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmatch_all\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:414\u001B[0m, in \u001B[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m    412\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 414\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:1321\u001B[0m, in \u001B[0;36mElasticsearch.delete_by_query\u001B[0;34m(self, index, allow_no_indices, analyze_wildcard, analyzer, conflicts, default_operator, df, error_trace, expand_wildcards, filter_path, from_, human, ignore_unavailable, lenient, max_docs, preference, pretty, q, query, refresh, request_cache, requests_per_second, routing, scroll, scroll_size, search_timeout, search_type, slice, slices, sort, stats, terminate_after, timeout, version, wait_for_active_shards, wait_for_completion)\u001B[0m\n\u001B[1;32m   1319\u001B[0m     __query[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwait_for_completion\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m wait_for_completion\n\u001B[1;32m   1320\u001B[0m __headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccept\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent-type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m-> 1321\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[return-value]\u001B[39;49;00m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPOST\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m__path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m__query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m__headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m__body\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:285\u001B[0m, in \u001B[0;36mBaseClient.perform_request\u001B[0;34m(self, method, path, params, headers, body)\u001B[0m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    283\u001B[0m     target \u001B[38;5;241m=\u001B[39m path\n\u001B[0;32m--> 285\u001B[0m meta, resp_body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_max_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_on_status\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_on_status\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_on_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_on_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client_meta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001B[39;00m\n\u001B[1;32m    298\u001B[0m \u001B[38;5;66;03m# since this is used as an 'exists' functionality.\u001B[39;00m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHEAD\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m meta\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m404\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m meta\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m299\u001B[39m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    305\u001B[0m     )\n\u001B[1;32m    306\u001B[0m ):\n",
      "File \u001B[0;32m/usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages/elastic_transport/_transport.py:329\u001B[0m, in \u001B[0;36mTransport.perform_request\u001B[0;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001B[0m\n\u001B[1;32m    327\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 329\u001B[0m     meta, raw_data \u001B[38;5;241m=\u001B[39m \u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m     _logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    337\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m [status:\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m duration:\u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124ms]\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    338\u001B[0m         \u001B[38;5;241m%\u001B[39m (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    344\u001B[0m         )\n\u001B[1;32m    345\u001B[0m     )\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHEAD\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/anaconda3/envs/DatahackSummitSemanticSearch/lib/python3.10/site-packages/elastic_transport/_node/_http_urllib3.py:199\u001B[0m, in \u001B[0;36mUrllib3HttpNode.perform_request\u001B[0;34m(self, method, target, body, headers, request_timeout)\u001B[0m\n\u001B[1;32m    191\u001B[0m         err \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mConnectionError\u001B[39;00m(\u001B[38;5;28mstr\u001B[39m(e), errors\u001B[38;5;241m=\u001B[39m(e,))\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_request(\n\u001B[1;32m    193\u001B[0m         method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    194\u001B[0m         target\u001B[38;5;241m=\u001B[39mtarget,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    197\u001B[0m         exception\u001B[38;5;241m=\u001B[39merr,\n\u001B[1;32m    198\u001B[0m     )\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    201\u001B[0m meta \u001B[38;5;241m=\u001B[39m ApiResponseMeta(\n\u001B[1;32m    202\u001B[0m     node\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig,\n\u001B[1;32m    203\u001B[0m     duration\u001B[38;5;241m=\u001B[39mduration,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    206\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresponse_headers,\n\u001B[1;32m    207\u001B[0m )\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_request(\n\u001B[1;32m    209\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    210\u001B[0m     target\u001B[38;5;241m=\u001B[39mtarget,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     response\u001B[38;5;241m=\u001B[39mdata,\n\u001B[1;32m    215\u001B[0m )\n",
      "\u001B[0;31mConnectionTimeout\u001B[0m: Connection timed out"
     ]
    }
   ],
   "source": [
    "elastic.delete_by_query(index=[index_name], body={\"query\": {\"match_all\": {}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0f4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.731116Z",
     "start_time": "2023-07-18T07:57:36.731076Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "elasticdb_gpt = ElasticVectorSearch.from_documents(\n",
    "    splits,\n",
    "    embedding,\n",
    "    index_name=index_name,\n",
    "    elasticsearch_url=\"http://localhost:9200\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfb775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.734744Z",
     "start_time": "2023-07-18T07:57:36.734712Z"
    }
   },
   "outputs": [],
   "source": [
    "elastic_vector_search = ElasticVectorSearch(\n",
    "            elasticsearch_url=\"http://localhost:9200\",\n",
    "            index_name=index_name,\n",
    "            embedding=embedding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608d527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.741914Z",
     "start_time": "2023-07-18T07:57:36.741873Z"
    }
   },
   "outputs": [],
   "source": [
    "elastic_vector_search_knn = ElasticKnnSearch(\n",
    "\n",
    "            es_connection=elasticdb_gpt.client,\n",
    "            index_name=index_name,\n",
    "            embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca66e3",
   "metadata": {},
   "source": [
    "##  Search\n",
    "\n",
    "When a query comes in we first convert it to a vector and then compare the vector to the elements in the database to get n most similar results.\n",
    "\n",
    "**Similarity Search**\n",
    "1. Similarity Search aims to find the most similar items to a given query in a dataset.\n",
    "2. It uses metrics like cosine similarity, Jaccard similarity, or Euclidean distance to quantify similarity.\n",
    "3. The search results are ranked based on their similarity scores, and the top-K items are returned.\n",
    "4. Use-cases: When the user's intent is clear and specific, similarity search is efficient. It's commonly used in standard search engines, recommendation systems, or any scenario where the goal is to find items most similar to the query.\n",
    "\n",
    "**Maximal Marginal Relevance (MMR) Search**\n",
    "1. MMR aims to provide a diverse set of results that are relevant to the query.\n",
    "2. Along with quantifying similarity to the query, MMR also considers similarity between items in the results set to ensure diversity.\n",
    "3. It aims to maximize the relevance of the returned items to the query, but also minimize the similarity between the returned items.\n",
    "4. Use-cases: When user intent is ambiguous or when there are multiple relevant responses, MMR can provide a more diverse set of results. It's useful in news article recommendation (to avoid recommending too many similar articles) or in conversational AI (to provide diverse responses).\n",
    "\n",
    "The choice between similarity search and MMR depends on the specific use case and user needs. If the aim is to provide a diverse set of results, MMR would be more suitable. If the goal is to find items most similar to the query, a similarity search would be more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93524545",
   "metadata": {},
   "source": [
    "### Keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556765f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.747484Z",
     "start_time": "2023-07-18T07:57:36.747452Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f1e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.751372Z",
     "start_time": "2023-07-18T07:57:36.751331Z"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f36b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.764430Z",
     "start_time": "2023-07-18T07:57:36.764370Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keyword search\n",
    "resp = elasticdb_gpt.client.search(q=\"Natural language processing\", query={\"match_all\": {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1f4e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.768666Z",
     "start_time": "2023-07-18T07:57:36.768629Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Got %d Hits:\" % resp['hits']['total']['value'])\n",
    "table = []\n",
    "for hit in resp['hits']['hits']:\n",
    "    table.append([hit['_source']['text'], hit['_score']])\n",
    "print(tabulate(table, headers=[\"text\", \"score\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d78c45",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2a094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.780763Z",
     "start_time": "2023-07-18T07:57:36.780695Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.similarity_search(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d83dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.785523Z",
     "start_time": "2023-07-18T07:57:36.785489Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.similarity_search_with_score(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470baeb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.788620Z",
     "start_time": "2023-07-18T07:57:36.788587Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.similarity_search(\"What is linear regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae07bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.799769Z",
     "start_time": "2023-07-18T07:57:36.799726Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticdb_gpt.similarity_search_with_score(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8d296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.835305Z",
     "start_time": "2023-07-18T07:57:36.835271Z"
    }
   },
   "outputs": [],
   "source": [
    "elastic_vector_search_knn.similarity_search_with_score(\"What is Natural language processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3099ef",
   "metadata": {},
   "source": [
    "### Maximum marginal relevance\n",
    "\n",
    "Maximum marginal relevance strives to achieve both relevance to the query and diversity among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764326d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.839439Z",
     "start_time": "2023-07-18T07:57:36.839414Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.max_marginal_relevance_search(\"What is linear regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35827dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.862088Z",
     "start_time": "2023-07-18T07:57:36.862046Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.max_marginal_relevance_search(\"What is natural language processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95f320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.875716Z",
     "start_time": "2023-07-18T07:57:36.875683Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.max_marginal_relevance_search(\"What is natural language processing\", filter={\"year\":1990})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc965eae",
   "metadata": {},
   "source": [
    "## Question and Answer\n",
    "\n",
    "\n",
    "When a query comes in we first convert it to a vector and then compare the vector to the elements in the database to get n most similar results. These results are then passed into prompt as a context for LLM to process them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51923140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.879128Z",
     "start_time": "2023-07-18T07:57:36.879067Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "def query_db(db, users_question, llm, filter={}):\n",
    "  # define the prompt template\n",
    "  template = \"\"\"\n",
    "  Given the following context sections, answer the\n",
    "  question using only the given context. If you are unsure and the answer is not\n",
    "  explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
    "\n",
    "  Context sections:\n",
    "  {context}\n",
    "\n",
    "  Question:\n",
    "  {users_question}\n",
    "\n",
    "  Answer:\n",
    "  \"\"\"\n",
    "  prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
    "    # use our vector store to find similar text chunks\n",
    "  results = db.similarity_search(\n",
    "      query=users_question,\n",
    "      n_results=10,\n",
    "      filter=filter\n",
    "  )\n",
    "\n",
    "  # fill the prompt template\n",
    "  prompt_text = prompt.format(context = results, users_question = users_question)\n",
    "\n",
    "  # ask the defined LLM\n",
    "  return llm(prompt_text)\n",
    "\n",
    "\n",
    "def query_db_relevance(db, users_question, llm, filter={}):\n",
    "  # define the prompt template\n",
    "  template = \"\"\"\n",
    "  Given the following context sections, answer the\n",
    "  question using only the given context. If you are unsure and the answer is not\n",
    "  explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
    "\n",
    "  Context sections:\n",
    "  {context}\n",
    "\n",
    "  Question:\n",
    "  {users_question}\n",
    "\n",
    "  Answer:\n",
    "  \"\"\"\n",
    "  prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
    "    # use our vector store to find similar text chunks\n",
    "  results = db.max_marginal_relevance_search(\n",
    "      query=users_question,\n",
    "      n_results=10,\n",
    "      filter=filter\n",
    "  )\n",
    "\n",
    "  # fill the prompt template\n",
    "  prompt_text = prompt.format(context = results, users_question = users_question)\n",
    "\n",
    "  # ask the defined LLM\n",
    "  return llm(prompt_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d64bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.883116Z",
     "start_time": "2023-07-18T07:57:36.882982Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(vectordb_gpt,\"What is linear regression?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5cadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.896444Z",
     "start_time": "2023-07-18T07:57:36.896401Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db_relevance(vectordb_gpt,\"What is linear regression?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94573f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.905109Z",
     "start_time": "2023-07-18T07:57:36.905083Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(elasticdb_gpt,\"What is linear regression?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787663b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.907926Z",
     "start_time": "2023-07-18T07:57:36.907904Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(vectordb_gpt,\"What is Natural language processing?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c172fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.911743Z",
     "start_time": "2023-07-18T07:57:36.911688Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(elasticdb_gpt,\"What is Natural language processing?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6df13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.914859Z",
     "start_time": "2023-07-18T07:57:36.914821Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(vectordb_gpt,\"What is Natural language processing?\" , llm, {\"year\":1990})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92850303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.918089Z",
     "start_time": "2023-07-18T07:57:36.918067Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(elasticdb_gpt,\"What is Natural language processing?\" , llm, {\"year\":1990})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c440512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.921006Z",
     "start_time": "2023-07-18T07:57:36.920978Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004813d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.924028Z",
     "start_time": "2023-07-18T07:57:36.923987Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db_relevance(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4a56c",
   "metadata": {},
   "source": [
    "## Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d871770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.928072Z",
     "start_time": "2023-07-18T07:57:36.928047Z"
    }
   },
   "outputs": [],
   "source": [
    "new_papers = [{\n",
    "    \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n",
    "    \"authors\": \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova\",\n",
    "    \"year\": 2018,\n",
    "    \"paper_id\": 7301,\n",
    "    \"abstract\": \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.\n",
    "BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).\n",
    "\"\"\"\n",
    "},\n",
    "  {\n",
    "      \"title\" : \"Evolution of transfer learning in natural language processing\",\n",
    "       \"authors\": \"Aditya Malte, Pratik Ratadiya\",\n",
    "      \"year\": 2019,\n",
    "       \"paper_id\": 7302,\n",
    "      \"abstract\": \"\"\"In this paper, we present a study of the recent advancements which have helped bring Transfer Learning to NLP through the use of semi-supervised training. We discuss cutting-edge methods and architectures such as BERT, GPT, ELMo, ULMFit among others. Classically, tasks in natural language processing have been performed through rule-based and statistical methodologies. However, owing to the vast nature of natural languages these methods do not generalise well and failed to learn the nuances of language. Thus machine learning algorithms such as Naive Bayes and decision trees coupled with traditional models such as Bag-of-Words and N-grams were used to usurp this problem. Eventually, with the advent of advanced recurrent neural network architectures such as the LSTM, we were able to achieve state-of-the-art performance in several natural language processing tasks such as text classification and machine translation. We talk about how Transfer Learning has brought about the well-known ImageNet moment for NLP. Several advanced architectures such as the Transformer and its variants have allowed practitioners to leverage knowledge gained from unrelated task to drastically fasten convergence and provide better performance on the target task. This survey represents an effort at providing a succinct yet complete understanding of the recent advances in natural language processing using deep learning in with a special focus on detailing transfer learning and its potential advantages.\n",
    "\"\"\"    \n",
    "  },\n",
    "  {\n",
    "       \"title\" : \"BERTQA -- Attention on Steroids\",\n",
    "       \"authors\": \"Ankit Chadha, Rewa Sood\",\n",
    "      \"year\": 2019,\n",
    "        \"paper_id\": 7303,\n",
    "      \"abstract\": \"\"\"In this work, we extend the Bidirectional Encoder Representations from Transformers (BERT) with an emphasis on directed coattention to obtain an improved F1 performance on the SQUAD2.0 dataset. The Transformer architecture on which BERT is based places hierarchical global attention on the concatenation of the context and query. Our additions to the BERT architecture augment this attention with a more focused context to query (C2Q) and query to context (Q2C) attention via a set of modified Transformer encoder units. In addition, we explore adding convolution-based feature extraction within the coattention architecture to add localized information to self-attention. We found that coattention significantly improves the no answer F1 by 4 points in the base and 1 point in the large architecture. After adding skip connections the no answer F1 improved further without causing an additional loss in has answer F1. The addition of localized feature extraction added to attention produced an overall dev F1 of 77.03 in the base architecture. We applied our findings to the large BERT model which contains twice as many layers and further used our own augmented version of the SQUAD 2.0 dataset created by back translation, which we have named SQUAD 2.Q. Finally, we performed hyperparameter tuning and ensembled our best models for a final F1/EM of 82.317/79.442 (Attention on Steroids, PCE Test Leaderboard).\n",
    "\"\"\"             \n",
    "  },\n",
    "    {\n",
    "        \"title\": \"BERT: A Review of Applications in Natural Language Processing and Understanding\",\n",
    "        \"authors\": \"Mikhail Koroteev\",\n",
    "        \"year\": 2021,\n",
    "        \"paper_id\": 7304,\n",
    "        \"abstract\": \"In this review, we describe the application of one of the most popular deep learning-based language models - BERT. The paper describes the mechanism of operation of this model, the main areas of its application to the tasks of text analytics, comparisons with similar models in each task, as well as a description of some proprietary models. In preparing this review, the data of several dozen original scientific articles published over the past few years, which attracted the most attention in the scientific community, were systematized. This survey will be useful to all students and researchers who want to get acquainted with the latest advances in the field of natural language text analysis.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981f3de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.931625Z",
     "start_time": "2023-07-18T07:57:36.931593Z"
    }
   },
   "outputs": [],
   "source": [
    "new_paper_df = pd.DataFrame(new_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f0e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.936602Z",
     "start_time": "2023-07-18T07:57:36.936579Z"
    }
   },
   "outputs": [],
   "source": [
    "new_paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce5812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.939554Z",
     "start_time": "2023-07-18T07:57:36.939530Z"
    }
   },
   "outputs": [],
   "source": [
    "loader_new = DataFrameLoader(new_paper_df, page_content_column=\"abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a69bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.947225Z",
     "start_time": "2023-07-18T07:57:36.947196Z"
    }
   },
   "outputs": [],
   "source": [
    "new_splits = sentence_spltter.split_documents(loader_new.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cad741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.957830Z",
     "start_time": "2023-07-18T07:57:36.957804Z"
    }
   },
   "outputs": [],
   "source": [
    "vectordb_gpt.add_documents(new_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1e8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.964964Z",
     "start_time": "2023-07-18T07:57:36.964935Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticdb_gpt.add_documents(new_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffced776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.972532Z",
     "start_time": "2023-07-18T07:57:36.972493Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd77b30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.976059Z",
     "start_time": "2023-07-18T07:57:36.976030Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db_relevance(vectordb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68327365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:36.981843Z",
     "start_time": "2023-07-18T07:57:36.981813Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db(elasticdb_gpt,\"What is BERT?\" , llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b596b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.013323Z",
     "start_time": "2023-07-18T07:57:37.013284Z"
    }
   },
   "outputs": [],
   "source": [
    "query_db_relevance(vectordb_gpt,\"How is bert an improvement?\" , llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b785909",
   "metadata": {},
   "source": [
    "## Chatting with your data: Final Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8daff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.015980Z",
     "start_time": "2023-07-18T07:57:37.015960Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccf78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.017859Z",
     "start_time": "2023-07-18T07:57:37.017834Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "retriever=vectordb_gpt.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797ac09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.020878Z",
     "start_time": "2023-07-18T07:57:37.020846Z"
    }
   },
   "outputs": [],
   "source": [
    "question = \"What is Natural language processing?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ffbf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.025064Z",
     "start_time": "2023-07-18T07:57:37.025026Z"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b9862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.029554Z",
     "start_time": "2023-07-18T07:57:37.029518Z"
    }
   },
   "outputs": [],
   "source": [
    "question = \"What are its real life applications?\"\n",
    "result2 = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38543a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.034175Z",
     "start_time": "2023-07-18T07:57:37.034099Z"
    }
   },
   "outputs": [],
   "source": [
    " result2[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9a92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.037839Z",
     "start_time": "2023-07-18T07:57:37.037817Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee95cfc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.040992Z",
     "start_time": "2023-07-18T07:57:37.040961Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def load_db(file, chain_type, k):\n",
    "    # create vector database from data\n",
    "    db = vectordb_gpt\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "#         return_generated_question=True,\n",
    "    )\n",
    "    return qa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c134b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.045814Z",
     "start_time": "2023-07-18T07:57:37.045784Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history_ui\",\n",
    "    return_messages=True\n",
    ")\n",
    "retriever=vectordb_gpt.as_retriever()\n",
    "    \n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=\"stuff\", \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "def chat(message, history=None):\n",
    "    history = history or []\n",
    "    response = qa({\"question\": message, \"chat_history\":history})['answer']\n",
    "    print(message, response, history)\n",
    "    history.append((message, response))\n",
    "    return history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71bb01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T07:57:37.051215Z",
     "start_time": "2023-07-18T07:57:37.051184Z"
    }
   },
   "outputs": [],
   "source": [
    "# collection.load()\n",
    "chatbot = gradio.Chatbot(color_map=(\"green\", \"gray\"))\n",
    "interface = gradio.Interface(\n",
    "    chat,\n",
    "    [\"text\", \"state\"],\n",
    "    [chatbot, \"state\"],\n",
    "    allow_screenshot=False,\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "interface.launch(inline=True, share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4b990",
   "metadata": {},
   "source": [
    "There are two arch types bert vs gpt : People would want to describe focus on architechtures\n",
    "\n",
    "1)why aare we doing preprocessing?\n",
    "\n",
    "2) MMR vs similarity searching\n",
    "\n",
    "3) Run the notebooks in advance. \n",
    "\n",
    "\n",
    "4) What gradio is. Add Gradio in slide\n",
    "\n",
    "5) COntext optimization big data approaches in slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead53220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DatahackSummitSemanticSearch",
   "language": "python",
   "name": "datahacksummitsemanticsearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
